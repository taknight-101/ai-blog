---
layout: post
title: "Oauth 2.0"
permalink: "ouauth"
categories: [Cyber Security, Protocols]
tags: ["utilities", "ut1", "js"] # TAG names should always be lowercase
# image: /images/utilities/1.jpg
---

## Preface

Hello again, this 1st blog in the cyber-security category will lay the groundwork for future sophisticated and rather complex topics to lay the foundation of many principles that are often used in the industry in different places and contexts, while being so critical that one misconfiguration or misunderstanding could lead to a potential attack or business risk that could even lead to a total business collapse. so it's not just very critical knowledge, best practices, foundational processes or various implementations, but also a rather important factor into any modern solution architecture in existence today.

## Intro

As the blog title conveys, we will be talking about the oauth2 protocol in the context of enterprise applications.

The approach i will take in this blog is that we won't explain formal definitions or provide opaque theories, but we will approach the topic in a more practical way with just enough history to set the stage right.

so with this out of the way, let's start with the topic

---

The purpose of authentication & authorization protocols is to provide a mechanism for implementing these 2 features in your application such that you are complying with security best practices and to make sure you are enforcing policy standards where each and every resource in your application is only allowed to be used by the right personas at the right time under the right circumstances.

And for the purposes of applications developed today, we can categorize them into 2 main types:

1. Internet applications
2. Enterprise applications

as their name implies, internet exposed apps imply in their operational business domain to be subject to public reach ,examples are social network applications such as Facebook, and twitter.

These applications still have their own protected resources that are only accessible through special permissions that need to be managed in a complete lifecycle from when the resource was created to the moment it's scheduled for deletion.

Also the same case applies for enterprise applications, though this type of applications have a more strict security boundary that they operate within and strict rules exist in place to make sure the process is not subject to security vulnerabilities or holes in the application itself or its integration or extensibility points

If we look at history, we see that implementing authentication and authorization protection was first a responsibility of the application itself, namely the application manages its own authentication and authorization information in its data sources and business rules, and it's the application responsibility to verify this information integrity, access grant, and violation rules.

This method exposed lots of issues as one could argue about the following:

- should credentials be sent to the application or separate entity like an identity provider as in essence it's a different responsibility than what the core business of the application provides?

- if credentials are managed by the application, exposing them to the ops/dev teams could lead to potential logging/leaking

- if we do offload the credentials management to a dedicated identity provider, enterprise applications's external access to identity providers still must be disallowed as the identity provider is a very sensitive entity that should be well hardened, unless the identity provider and the application are co-located in the same data center's security boundary be it physical or logical through a virtual private network

- the application still is the sole owner of its defined business rules and permissions through which it chooses to grant which access to whom , complying with
  practices like the principle of least privilege

For the mentioned points above, devised solutions were implemented to provide distinct identity responsibility segregation in a separate entity while still providing a secure implementation of communication between it and the application whose sole purpose is to manage authorization as authorization is always the application responsibility as it knows best the business rules to handle the functions supplied by the app for its different use cases based on the information retrieved from the identity provider for the user

And as for direct access from application to identity providers when they are on the same network , a devised TCP based protocol called LDAP is implemented for the direct identity access and one of its most famous identity providers is microsoft's active directory

But what if the application is deployed to a different data center, provided the evolution and rapid explosion of cloud based application deployments, how can we still maintain secure authentication & authorization in this setting

and here came to the picture another protocol called SAML that solved the following problems:

1. communication across data centers through HTTP redirects
2. sending/exposing credentials to the application while it's not its core concern as we mentioned

For that to happen, SAML setup needs to be in place:

An application needs to integrate as a SAML service provider, namely an install/exchange of SAML meta data between SAML identity provider & service provider must be established for trust through a browser HTTP redirects, and as the user is already domain joined and logged in, the SAML identity provider will recognize that and send the service provider the information it needs in a SAML token in a form of SAML attribute claims.

in SAML application provider is called SAML service provider as :
it needs to establish trust between it and SAML identity provider as SAML IP encrypts and signs the SAML response with its certificates which the application needs to know and have exchanged in SAML meta data exchange in order to decrypt the response and extracts the SAML token within the response that contains claims "user attributes"

> SAML identity provider most commonly used is microsoft ADFS "active directory federation service" and is built on top of LDAP AD
> when user is at the same network as the identity provider => LDAP is normally used
> {: .prompt-tip }

> So to recall
> SAML is used where:
> the client is domain-joined to the network into which the authorization server "identity provider" exists and thus when the client is already network connected, the auth-server "in this case SAML ADFS" assumes the user logged-in or authenticated thus sending the required credentials to the requesting application, so automatic authorization takes place and the scopes are to be set automatically based on the user active directory roles unlike manual scopes used on oauth2 based on resource owner consent "more on that later"

Simply put --> the client + the resource server "application or SAML service provider" and the authorization server "SAML ADFS" are ALL controlled by the SAME company -This is so important to make note of- and there is no notion of 3rd party application access as in oauth2, and this is always the case in enterprise applications

Note that the SAML implementation centralizes the authentication & authorization concerns to the SAML identity provider where all applications whether deployed in the same data center or in the cloud references for their identity , hence the user is federated through the single identity from different applications, this is called single sign on or SSO

> Federated user means same user identity which are being used by all other applications  
> {: .prompt-tip }

That's fine in use cases like if the cloud application is a monolithic application deployed as a single application service/process or if the business application doesn't require delegated trust between itself and other resource servers like social logins

So to outline the above problems as SAML limitations we elaborate the following:

- SAML token that contains the user claims is LARGE in size, and to pass it on to application services(micro-service) would be a great overhead

- in general terms, how to secure REST APIs behind SAML service providers like cron jobs that need to talk to protected REST APIs in a transitive authority grant

- what if your 3rd party developed app needs to publish a post on your behalf to your linked in profile "completed a certification for instance" how does linked in trust/authorizes your 3rd party application with its protected REST-api to perform some actions on your behalf?

Simple answer is: SAML was not designed to protect REST-apis

and here comes the solution and the main topic for this blog, Meet the Oauth2.0 protocol

---

> Before we begin there are some oauth2 glossary that need to be defined as we will mention them many times in the upcoming sections

Connecting analogy with the above mentioned example of social authorization in linked in via your custom developed application:

- Resource owner| you | the linked in profile owner, that's your resource
- http service | resource server | rest api | the linked in protected rest api
- oauth2 authorization server | tied to the resource -in linkedin- | A 1:1 relationship between resource server and its authorization server
- 3rd party app | client | your custom developed app

- Authorization in oauth2 is different from the vanilla authorization term often mentioned alongside authentication
  in oauth context , it refers to your consent "permissions" on allowing a 3rd party app to access your resources from the resource server >> giving by your the resource owner <<

### Client Registration:

> There are many flows in oauth2 .Each flow would have different client registration attributes

how would the auth server identify the connected client as a valid one and not a rouge client
after client registration in the auth server , the client gets a client-id and a client-secret to identity itself to the auth-server from now on

resource server talks to auth-server for token verification "as it's an opaque token <string> and the actual mapping of the token to its related security attributes/claims is maintained in the auth-server" and to retrive scopes of the resource server to use for resource authoirzation
structured access token "jwt" token solves the above problem that could cause auth-server downtime due to many flooding token verification requests from multiple clients to the token verification endpoint "called introspect endpoint"
structured access token : carries token information + resource scopes to be used by the resource server "in the <scp> property "

how then resource server verify the token in case of structured token? as it's still encrypted and signed by the auth-server private key?!
answer is that auth-server provides an end point to retrieve the public signing key "all those" for the resource server to use to verify the token "eariler and caches them in the resourse server" , but the performance win here is that resource server doesn't have to do this for every client request!! unlike the previous opaque token case

note that ouath2 is a security protocol standard that all authorization servers have to abide by by implementing its defined endpoints , url names might be different but params are standard and defined in RFC

In case of Google APIs, the scopes look like URLs but they don't have to be. Scopes can be any string and when we create our own Resource Server we will see how to create our own scopes.
There is an additional Endpoint which is not shown in the previous lecture - the Token Revocation endpoint. Using the Token Revocation endpoint, a client can invalidate an access token and other related tokens. It's used for cleanup after a user logs out of the client application and in cases where the token is suspected of being compromised

> Front channel: from front-end to auth-server, so front-end is involved in the communication <br>
> Back channel : from back-end to auth-serve
> {: .prompt-tip }

a client in oauth is an application that can request an access token from an auth-server , that's it :-
types of client in oauth:

1. confidential client: like ur custom web server u developed
2. public client : run in an insecure environment like your browser like frontends <web, mobile, desktop>

---

Before we proceed, we've mentioned browser and http redirects so many times, and as it's crucial to the overall understanding of oauth grant type flows, it's important to take some time to explain this mechanism in a little more detail

for that, i prepared a simple example depicted in the following diagram,

![]({{ site.baseurl }}/images/oauth/poc1.png)

this example demonstrates how http redirects behave and covers typically the first steps in a typical oauth grant type flow, like for example the authorization code grant flow

The example features a user agent simulated as a curl user agent which initiates a request to obtain a secret from the server application being a simple python server which doesn't possess the secret and is not meant for that so it in turn redirects the curl request to the auth server that's entitled to serve the secret being in this case a configured webhook in [webhook.site](https://webhook.site/) which in turn redirects back to the python server with the requested secret associated in a query string to the callback endpoint the server listens on to process the secret and perform any further business logic as the secret is now obtained and assumed valid.

So, to set up this showcase demo, you'll need to:

1. Create a simple Python server to handle HTTP requests and perform redirects.
2. Use an online webhook service that can respond with a simulated payload.
3. Use curl to send HTTP requests

Here's a step-by-step guide to achieve this:

Step 1: Set Up the Simple Python Server
Create a Python script for the server that listens for HTTP requests and redirects them to a webhook.

```python
from http.server import BaseHTTPRequestHandler, HTTPServer

AUTH_SERVER_URL = "https://webhook.site/01b89891-d9ab-45eb-8a17-4381d1c1f925"  # Replace with your unique URL from webhook.site

class RedirectHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path == "/authorize":
            # Redirect to the authorization server (simulated)
            self.send_response(302)
            self.send_header('Location', AUTH_SERVER_URL)
            self.end_headers()
        elif self.path.startswith("/callback"):
            # Extract the auth code from the query string
            auth_code = self.path.split("code=")[-1]
            print(f'Got Auth_code= {auth_code}')
            self.send_response(200)
        else:
            self.send_response(404)
            self.end_headers()

def run(server_class=HTTPServer, handler_class=RedirectHandler, port=8080):
    server_address = ('', port)
    httpd = server_class(server_address, handler_class)
    print(f'Starting server on port {port}...')
    httpd.serve_forever()

if __name__ == "__main__":
    run()

```

Then run the python server with the following command

```sh
python poc.py
```

Step 2: Use an Online Webhook Service
Webhook Service: We use Webhook.site in this example to create a unique URL that will simulate the OAuth2 authorization server response.

![]({{ site.baseurl }}/images/oauth/poc1.1.png)

![]({{ site.baseurl }}/images/oauth/poc1.2.png)

Step 3: Use curl to Make HTTP Requests: Use the following curl commands to demonstrate the process and display raw HTTP headers.

```sh
curl -v -L "http://localhost:8080/authorize"
```

the -L command option is crucial to allow curl to follow redirects in response headers to the Location header URL

End Result

![]({{ site.baseurl }}/images/oauth/poc.gif)

> Bearer token means: give access to the bearer of this token no matter who is calling it
> {: .prompt-tip }

////////

---

> See you in the next one 👋

```

```
